

**性能调优的最终目的，是在所有参与计算的硬件资源之间寻求协同与平衡，让硬件资源达到一种平衡、无瓶颈的状态**。对于 CPU 来说，最需要协同和平衡的硬件资源非内存莫属。原因主要有两方面：一方面，在处理延迟方面，只有内存能望其项背；另一方面，在主板上内存通过数据总线直接向 CPU 寄存器供给数据。因此，理顺它们之间的关系，可以为性能调优奠定更好的基础。

### CPU 与内存的平衡本质上是什么？

我们知道，Spark 将内存分成了 Execution Memory 和 Storage Memory 两类，分别用于分布式任务执行和 RDD 缓存。其中，RDD 缓存虽然最终占用的是 Storage Memory，但在 RDD 展开（Unroll）之前，计算任务消耗的还是 Execution Memory。因此，**Spark 中 CPU 与内存的平衡，其实就是 CPU 与执行内存之间的协同与配比。要想平衡 CPU 与执行内存之间的协同和配比**，我们需要使用 3 类配置参数，它们分别控制着并行度、执行内存大小和集群的并行计算能力。只有它们设置得当，CPU 和执行内存才能同时得到充分利用。否则 CPU 与执行内存之间的平衡就会被打破，要么 CPU 工作不饱和，要么 OOM 内存溢出。想要知道这 3 类参数都包含哪些具体的配置项，以及它们到底是怎么配置的，我们需要先弄清楚一些基础知识，也就是并行计算的线程之间是如何瓜分执行内存的。

那么，执行内存抢占规则就是，在同一个 Executor 中，当有多个（记为 N）线程尝试抢占执行内存时，需要遵循 2 条基本原则：执行内存总大小（记为 M）为两部分之和，一部分是 Execution Memory 初始大小，另一部分是 Storage Memory 剩余空间每个线程分到的可用内存有一定的上下限，下限是 M/N/2，上限是 M/N，也就是均值

### 三足鼎立：并行度、并发度与执行内存

- 并行度：

  并行度指的是为了实现分布式计算，分布式数据集被划分出来的份数。并行度明确了数据划分的粒度：**并行度越高，数据的粒度越细，数据分片越多，数据越分散。**

  - 并行度设置
    - RDD默认并行度：spark.default.parallelism
    - Shuffle Reduce 默认并行度：spark.sql.shuffle.partitions



- 并发度：**同一时间内，一个 Executor 内部可以同时运行的最大任务数量**，Executor 的线程池大小由参数 spark.executor.cores 决定，每个任务在执行期间需要消耗的线程数由 spark.task.cpus 配置项给定。两者相除得到的商就是并发度，又因为，spark.task.cpus 默认数值为 1，并且通常不需要调整，所以，并发度基本由 spark.executor.cores 参数敲定。

  

  就 Executor 的线程池来说，尽管线程本身可以复用，但每个线程在同一时间只能计算一个任务，每个任务负责处理一个数据分片。因此，**在运行时，线程、任务与分区是一一对应的关系。**

  分布式任务由 Driver 分发到 Executor 后，Executor 将 Task 封装为 TaskRunner，然后将其交给可回收缓存线程池（newCachedThreadPool）。线程池中的线程领取到 TaskRunner 之后，向 Execution Memory 申请内存，然后开始执行任务。

**可分配的执行内存总量会随着缓存任务和执行任务的此消彼长，而动态变化。但无论怎么变，可用的执行内存总量，都不会低于配置项设定的初始值。**

堆内执行内存的初始值由很多参数共同决定，具体的计算公式是：spark.executor.memory * spark.memory.fraction * (1 - spark.memory.storageFraction)。相比之下，堆外执行内存的计算稍微简单一些：spark.memory.offHeap.size * (1 - spark.memory.storageFraction)。



### CPU低效原因之一：线程挂起

在给定执行内存总量 M 和线程总数 N 的情况下，为了保证每个线程都有机会拿到适量的内存去处理数据，Spark 用 HashMap 数据结构，以（Key，Value）的方式来记录每个线程消耗的内存大小，并确保所有的 Value 值都不超过 M/N。在一些极端情况下，有些线程申请不到所需的内存空间，能拿到的内存合计还不到 M/N/2。这个时候，Spark 就会把线程挂起，直到其他线程释放了足够的内存空间为止。

你可能会问：“既然每个线程能拿到的内存上限是 M/N，也就是内存总量对线程数取平均值，为什么还会出现有的线程连 M/N/2 都拿不到呢？这在数学上也不成立呀！”这是个好问题。这种情况的出现，源于 3 方面的变化和作用：

- 动态变化的执行内存总量 M

- 动态变化的并发度 N~

- 分布式数据集的数据分布

首先，动态变化的执行内存总量 M 我们刚刚已经说过了。M 的下限是 Execution Memory 初始值，上限是 spark.executor.memory * spark.memory.fraction 划定的所有内存区域。在应用刚刚开始执行的时候，M 的取值就是这个上限，但随着 RDD 缓存逐渐填充 Storage Memory，M 的取值也会跟着回撤。

另外，到目前为止，（1/N/2，1/N）上下限的计算我们用的都是线程总数 N，线程总数 N 是固定的。N 的取值含义是一个 Executor 内最大的并发度，更严格的计算公式是 spark.executor.cores 除以 spark.task.cpus。但实际上，上下限公式的计算用的不是 N，而是 N~。N~ 的含义是 Executor 内当前的并发度，也就是 Executor 中当前并行执行的任务数。显然 N~ <= N。

换句话说，尽管一个 Executor 中有 N 个 CPU 线程，但这 N 个线程不一定都在干活。在 Spark 任务调度的过程中，这 N 个线程不见得能同时拿到分布式任务，所以先拿到任务的线程就有机会申请到更多的内存。在某些极端的情况下，后拿到任务的线程甚至连一寸内存都申请不到。不过，随着任务执行和任务调度的推进，N~ 会迅速地趋近于 N，CPU 线程挂起和内存分配的情况也会逐渐得到改善。

第三个影响任务并发度和内存分配的因素，是分布式数据集的分布情况。数据分片的数据量决定了执行任务需要申请多少内存。如果分布式数据集的并行度设置得当，因任务调度滞后而导致的线程挂起问题就会得到缓解



### CPU 低效原因之二：调度开销

线程挂起的问题得到缓解，CPU 利用率就会有所改善。既然如此，是不是把并行度设置到最大，每个数据分片就都能足够小，小到每个 CPU 线程都能申请到内存，线程不再挂起就万事大吉了呢？

当然不是，并行度足够大，确实会让数据分片更分散、数据粒度更细，因此，每个执行任务所需消耗的内存更少。但是，**数据过于分散会带来严重的副作用：调度开销骤增**。

对于每一个分布式任务，Dirver 会将其封装为 TaskDescription，然后分发给各个 Executor。TaskDescription 包含着与任务运行有关的所有信息，如任务 ID、尝试 ID、要处理的数据分片 ID、开发者添加的本地文件和 Jar 包、任务属性、序列化的任务代码等等。Executor 接收到 TaskDescription 之后，首先需要对 TaskDescription 反序列化才能读取任务信息，然后将任务代码再反序列化得到可执行代码，最后再结合其他任务信息创建 TaskRunner。

因此你看，每个任务的调度与执行都需要 Executor 消耗 CPU 去执行上述一系列的操作步骤。数据分片与线程、执行任务一一对应，当数据过于分散，分布式任务数量会大幅增加，但每个任务需要处理的数据量却少之又少，就 CPU 消耗来说，相比花在数据处理上的比例，任务调度上的开销几乎与之分庭抗礼。显然，在这种情况下，CPU 的有效利用率也是极低的。

### 如何优化 CPU 利用率？

你可能会说：“这也太尴尬了，并行度低了不行，容易让 CPU 线程挂起；高了也不行，调度开销太大，CPU 有效利用率也不高。高也不行、低也不行，那我该怎么办呢？”

因此，在给定 Executor 线程池和执行内存大小的时候，我们可以参考上面的算法，去计算一个能够**让数据分片平均大小在（M/N/2, M/N）之间的并行度，这往往是个不错的选择。**

总的来说，对 CPU 利用率来说，并行度、并发度与执行内存的关系就好像是一尊盛满沸水的三足鼎，三足齐平则万事大吉，但凡哪一方瘸腿儿，鼎内的沸水就会倾出伤及无辜。

<img src="https://static001.geekbang.org/resource/image/4a/ce/4a5dc54813346924ec5611f6d1fa8fce.jpg?wh=4101*1043" alt="img" style="zoom:25%;" />

### 小结

今天这一讲，我们从 CPU 与执行内存平衡的角度，通过梳理 Executor 并行度、并发度和执行内存之间的关系，以及它们对 CPU 利用率的影响，总结出了有效提升 CPU 利用率的方法。

首先，在一个 Executor 中，每个 CPU 线程能够申请到的内存比例是有上下限的，最高不超过 1/N，最低不少于 1/N/2，其中 N 代表线程池大小。

其次，在给定线程池大小和执行内存的时候，并行度较低、数据分片较大容易导致 CPU 线程挂起，线程频繁挂起不利于提升 CPU 利用率，而并行度过高、数据过于分散会让调度开销更显著，也不利于提升 CPU 利用率。

最后，在给定执行内存 M、线程池大小 N 和数据总量 D 的时候，想要有效地提升 CPU 利用率，我们就要计算出最佳并行度 P，计算方法是让数据分片的平均大小 D/P 坐落在（M/N/2, M/N）区间。这样，在运行时，我们的 CPU 利用率往往不会太差。

### 问答

1. 从 Executor 并发度、执行内存大小和分布式任务并行度出发，你认为在什么情况下会出现 OOM 的问题？
   - 在每个线程都分配到了最大内存，即 M/N 的内存时，如果 task 还需要更多的内存，那么就会发生 OOM。
   - 在每个线程都分配到了最少内存，即 M/2N的内存时，如果 task 还需要更多的内存，此时又没有其他线程释放内存供其使用，那么也会导致OOM。
2. 由于执行内存总量 M 是动态变化的，并发任务数 N~ 也是动态变化的，因此每个线程申请内存的上下限也是动态调整的，你知道这个调整周期以什么为准？
   - 其实在 task 每次的 allocatePage，都会动态计算 task 当先的上下限的申请大小。满足申请条件，返回。申请后可用大小加上当前已用不满足下限，则挂起等待其它 task 唤醒抢占。

